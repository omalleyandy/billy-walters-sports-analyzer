# Overtime.ag Scraper - Quick Start Guide

## üöÄ Get Started in 3 Minutes

### Step 1: Setup (One-Time)
```powershell
# Install dependencies
uv sync

# Install browser for scraping
uv run playwright install chromium

# Copy environment template and add your credentials
cp env.template .env
# Edit .env and add your OV_CUSTOMER_ID and OV_CUSTOMER_PASSWORD
```

### Step 2: Run Your First Scrape
```powershell
# Scrape both NFL and College Football pre-game odds
uv run walters-analyzer scrape-overtime
```

That's it! Check `data/overtime_live/` for your results.

---

## üìã Common Commands

### Pre-Game Odds (Main Use Case)
```powershell
# Both sports (default)
uv run walters-analyzer scrape-overtime

# NFL only
uv run walters-analyzer scrape-overtime --sport nfl

# College Football only
uv run walters-analyzer scrape-overtime --sport cfb
```

### Live Betting Odds
```powershell
# Currently live games
uv run walters-analyzer scrape-overtime --live
```

---

## üìÅ Output Files

After each scrape, you'll find 3 files in `data/overtime_live/`:

1. **CSV** (`overtime-live-{timestamp}.csv`) 
   - Open in Excel
   - Easy to read and analyze
   - All odds in separate columns

2. **JSONL** (`overtime-live-{timestamp}.jsonl`)
   - One game per line
   - Full nested data structure
   - Easy to process programmatically

3. **Parquet** (`overtime-live-{timestamp}.parquet`)
   - Efficient columnar format
   - Best for data analysis with pandas/polars
   - Smallest file size

---

## üîç Example: View Your Data

### In Python
```python
import pandas as pd

# Read CSV
df = pd.read_csv('data/overtime_live/overtime-live-20251101-120000.csv')
print(df[['away_team', 'home_team', 'spread_away_line', 'spread_away_price']])

# Or read Parquet (faster for large files)
df = pd.read_parquet('data/overtime_live/overtime-live-20251101-120000.parquet')
```

### In Excel
1. Open the CSV file directly
2. Each game is one row
3. Odds are in separate columns for easy filtering/sorting

---

## ‚öôÔ∏è Environment Variables

Edit your `.env` file with these required credentials:

```bash
OV_CUSTOMER_ID=your_customer_id_here
OV_CUSTOMER_PASSWORD=your_password_here
```

**Where to find these:**
1. Go to https://overtime.ag
2. Your customer ID is your login username
3. Use your account password

---

## üêõ Troubleshooting

### "Login failed"
- Double-check your credentials in `.env`
- Try logging in manually at overtime.ag to verify they work
- Make sure there are no extra spaces in your `.env` file

### "scrapy command not found"
```powershell
uv sync  # Re-run to ensure all dependencies are installed
```

### "Browser not found"
```powershell
uv run playwright install chromium
```

### Want to see what's happening?
- Check `snapshots/` folder for debug screenshots
- Look at the console output for detailed logs

---

## üìä What Data Do I Get?

For each game, you'll get:

**Game Info**
- Teams (home and away)
- Rotation numbers (e.g., "451-452")
- Date and time (e.g., "2025-11-02" and "1:00 PM ET")

**Betting Odds**
- **Spread**: Line and price for both teams
- **Total**: Over/Under line and prices
- **Moneyline**: Odds for both teams

**Example CSV Row:**
```
away_team: Chicago Bears
home_team: Cincinnati Bengals
rotation_number: 451-452
spread_away_line: -2.5
spread_away_price: -115
spread_home_line: +2.5
spread_home_price: -105
total_over_line: 51
total_over_price: -110
...
```

---

## üéØ Pro Tips

1. **Schedule Regular Scrapes**: Use Windows Task Scheduler or cron to run scrapes automatically
2. **Compare Across Time**: Keep old files to track line movements
3. **Filter by Sport**: Use `--sport nfl` or `--sport cfb` for faster, focused scrapes
4. **Custom Output**: Use `--output-dir ./my_data` to organize by date or purpose

---

## üí° Example Workflow

```powershell
# Morning: Scrape pre-game odds
uv run walters-analyzer scrape-overtime --sport nfl

# Analyze in Excel or Python
# ...

# During games: Check live betting
uv run walters-analyzer scrape-overtime --live

# Compare pre-game vs live odds
# Identify value opportunities
```

---

## üìö Need More Help?

- See `README.md` for detailed documentation
- Check `IMPLEMENTATION_SUMMARY.md` for technical details
- Review log output for specific error messages
- Inspect `snapshots/` folder for visual debugging

---

## ‚úÖ Quick Checklist

Before running your first scrape:
- [ ] Installed dependencies (`uv sync`)
- [ ] Installed Playwright (`uv run playwright install chromium`)
- [ ] Created `.env` file from `env.template`
- [ ] Added your `OV_CUSTOMER_ID` and `OV_CUSTOMER_PASSWORD`
- [ ] Ready to run: `uv run walters-analyzer scrape-overtime`

**Happy scraping! üé≤**

